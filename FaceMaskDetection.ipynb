{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPz842MoGVcRbWv7C+aOGpP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asafct2003/DEEP_LEARNING/blob/main/FaceMaskDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulEpEn0Jh48-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"omkargurav/face-mask-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "TrEJXvexiIm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "\n",
        "# Set dataset path\n",
        "dataset_path = os.path.join(path, \"data\")   # using kagglehub 'path'\n",
        "\n",
        "with_mask_path = os.path.join(dataset_path, \"with_mask\")\n",
        "without_mask_path = os.path.join(dataset_path, \"without_mask\")\n",
        "\n",
        "# Get file names\n",
        "with_mask_images = os.listdir(with_mask_path)[:5]       # first 5 images\n",
        "without_mask_images = os.listdir(without_mask_path)[:5] # first 5 images\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Display With Mask\n",
        "for i, img_name in enumerate(with_mask_images):\n",
        "    img = imread(os.path.join(with_mask_path, img_name))\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(\"With Mask\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "# Display Without Mask\n",
        "for i, img_name in enumerate(without_mask_images):\n",
        "    img = imread(os.path.join(without_mask_path, img_name))\n",
        "    plt.subplot(2, 5, i+6)\n",
        "    plt.imshow(img)\n",
        "    plt.title(\"Without Mask\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sPX7M7qfiKM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 150\n",
        "batch_size = 32\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.20,    # 20% for testing\n",
        "    rotation_range=15,\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "train_data = datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "test_data = datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "id": "0roTr3MbiMpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "VDP3j3xLiPT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_data,\n",
        "    epochs=15,\n",
        "    validation_data=test_data\n",
        ")\n"
      ],
      "metadata": {
        "id": "eN_510PxiRVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(test_data)\n",
        "print(\"Test Accuracy:\", acc)"
      ],
      "metadata": {
        "id": "vdumnHXQiWma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "img_path = \"/content/OIP mask.jpg\"   # your image file\n",
        "\n",
        "# Load and preprocess\n",
        "img = image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_expanded = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Predict\n",
        "prediction = model.predict(img_expanded)[0][0]\n",
        "\n",
        "# Display image\n",
        "plt.imshow(img)\n",
        "plt.title(\"Input Image\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Print prediction\n",
        "if prediction < 0.5:\n",
        "    print(\"Mask Detected ðŸ˜·\")\n",
        "else:\n",
        "    print(\"No Mask Detected ðŸ˜\")"
      ],
      "metadata": {
        "id": "bnyPVXTHiYbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "img_path = \"/content/OIP withoutmask.jpg\"   # your image file\n",
        "\n",
        "# Load and preprocess\n",
        "img = image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_expanded = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Predict\n",
        "prediction = model.predict(img_expanded)[0][0]\n",
        "\n",
        "# Display image\n",
        "plt.imshow(img)\n",
        "plt.title(\"Input Image\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Print prediction\n",
        "if prediction < 0.5:\n",
        "    print(\"Mask Detected ðŸ˜·\")\n",
        "else:\n",
        "    print(\"No Mask Detected ðŸ˜\")"
      ],
      "metadata": {
        "id": "FYGThxqnneTK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}